% The template was derived from the LaTeX template for Workshop on Formal Verification and Machine Learning (WFVML).

\documentclass[nohyperref]{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{classproject} with \usepackage[nohyperref]{classproject2025} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{classproject}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \classprojecttitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\classprojecttitlerunning{ECE 584 Class Project Proposal}
\bibliographystyle{plainnat}
\begin{document}

\twocolumn[
\classprojecttitle{ECE 584 Class Project Proposal}

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\classprojectsetsymbol{equal}{*}

\begin{classprojectauthorlist}
\classprojectauthor{Arjun Vedantham}{}
%\classprojectauthor{}{sch}
%\classprojectauthor{}{sch}
\end{classprojectauthorlist}

\classprojectcorrespondingauthor{Arjun Vedantham}{arjunsv2@illinois.edu}


% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\classprojectkeywords{Machine Learning, Formal Verification (replace with yours)}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \classprojectEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{} % otherwise use the standard text.

% \begin{abstract}
% This document provides a basic template for your class project proposal or final report.
% The project proposal is limited to 4 pages and final report is limited to 6 pages (references and appendix excluded). You can have unlimited number of pages for references or appendix. 
% The project proposal submission deadline is \textbf{March 03, 2025}.
% \end{abstract}

\section{Introduction}

GPUs have become a critical infrastructure component of any high performance computing cluster. Much of the code targeting GPUs leverages CUDA, ROCm, and other GPU-specific programming frameworks that have unique 
behaviors that may lead to common bugs or performance inefficiencies. For instance, programmers can easily miscalculate the memory address required by each thread to access its working set. 
Given these common classes of bugs, we would like to examine using verification tools to validate the correctness of GPU kernel code. 
Specifically, we would like to target kernel implementations generated by large language models, since these have increased the expressivity of synthesis tools to beyond what was previously capable with constraint solver guided program synthesis. \cite{solar-lezama_introduction_2025}

\section{Problem statement}
Given generated GPU kernels, we want to verify both the correctness and performance aspects of the generated code. On the correctness end, we would like to verify safety constraints such as "there are no out of bounds memory accesses". Additionally, we plan to consider liveness properties could include
constraints that we would like our generated kernel implementation to meet, like maximizing the number of accesses made to shared memory, while minimizing more expensive global memory accesses.  

\section{Related work}
There are numerous papers on LLM-guided program synthesis, including with respect to GPU kernels. Traditional GPU verification tools include GPUVerify \cite{betts_gpuverify_2012}, which checks for data races and other types of unsafe memory behavior. More recent work has examined the role of LLMs in kernel code generation - for instance, a team at SJTU compared LLM-generated code with
human written versions to verify their correctness, using a heuristic to ensure that LLM generated kernel implementations did not produce results that deviated far from the ground-truth human written examples \cite{chen_cuda-llm_2025}. In addition, it incorporated some runtime performance feedback to guide the LLM's synthesis process towards more efficient kernel implementations. KernelBench \cite{ouyang_kernelbench_2025}
is another framework for automated performance optimization of GPU kernels, however, it primarily relies on wall-clock time as its main feedback, and does not incorporate any ground-truth kernel implementations - in fact, the authors specifically mention leveraging formal verification to provide stronger correctness guarantees. Finally, a project named SHARD \cite{zhao_shard_2025} focused on formalizing security guarantees for GPU kernels, using Dafny and Verus to actually handle the correctness checks. 

\section{Methodology}

We would like to start by taking LLM-generated GPU kernels for simple tasks (e.g. tiled matrix multiplication), and adding formal safety guarantees in a verification language like Dafny, similar to the approach described in the SHARD paper. Dafny has plenty of features for stating loop invariants, pre and post-conditions, etc.
Due to the extensive scope of potential bugs in the CUDA ecosystem, we would like to initially focus on verifying the absence of memory indexing bugs (the "memory model" category as described in table 1 of the SHARD paper). Modeling our approach after the SHARD paper, we would formulate this as a Hoare triple, which we would then discharge in Dafny. Once these safety guarantees are implemented, we would then explore verifying specific performance-centric behavior. 
For instance, we would like to use inductive invariants to formally prove a bound on the number of global memory accesses for a specific kernel. 

Since capturing the behavior of the GPU kernel within Dafny may be difficult, an alternative approach could be to simply add constraints about how each thread calculates its memory address, and pass this to an SMT solver (like Z3) to verify that the block or thread-specific memory bounds are not violated. However, since Z3 is less expressive than Dafny, it may be more difficult to leverage the Z3 abstractions to prove runtime characteristics, like bounding the number of global memory accesses. 

% Name the tools or algorithms that may be helpful for solving your problem in your project proposal.

% Discuss the algorithms and tools you used to solve your problem in the final report.

% Evaluate the technical risks of your project - if the proposed methodology does not work, what are the potential causes?

\section{Results}
In the end, what we hope to achieve is:
\begin{itemize}
    \item A framework for extracting kernel launch parameters and moving them into Dafny (2025-10-16)
    \item Leveraging this framework to state and prove safety invariants about how the kernel accesses memory - e.g. verifying that there are no out-of-bounds memory accesses based on the launch parameters (2025-11-01)
    \item Stating and proving general performance or behavior constraints - e.g. bounding the number of global memory accesses. This expressivity improvement will be the main focus of our project. 
\end{itemize}

Although fine-tuning the LLM output by providing feedback is not a primary goal of this project, we would also be interested in seeing if any violations of safety or liveness constraints could be added as synthesis constraints in the form of a new prompt. 

% For project proposal: give your timeline and targets (what goals do you aim to achieve? what are the deliverables?)

% For final report: report your findings and summarize your results.

% In general, your final report should look similar to an academic paper published at a first-tier conference or journal.
% In our class, you have been assigned several papers to read. Your final report should look similar to these papers you have read.

\bibliography{example_paper}
\end{document}



% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2023. 
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
